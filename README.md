# NLP
This project has Three parts 1. Load the dataset, create train, validation and test splits. Preprocess the dataset as required to train a decoder model 
2.Create a decoder model and train it using the joke-dataset. Try out different hyperparameters for the model, like the number of decoder blocks, hidden dimension, sequence length etc. Choose the model which gives you the best results. Log the results for the different hyperparameters combinations used. 
3.Finetune a GPT-2 model using the dataset and compare the responses of your model and the finetuned GPT-2 model
# DATASET 
The dataset comprises of reddit,stuppidstuff,wocka jokes.https://github.com/taivop/joke-dataset
